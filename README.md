# ğŸ›¡ï¸ AI-Driven DevSecOps Security Policy Generator

**Final Project 2025/2026 - 3GL**

Automated security policy generation from vulnerability reports using LLMs (GPT-4, Claude, DeepSeek).

## ğŸ“‹ Project Overview

This project transforms technical vulnerability reports (SAST, SCA, DAST) into human-readable security policies compliant with NIST CSF and ISO/IEC 27001 using Large Language Models.

**Target Application:** OWASP Juice Shop (Node.js e-commerce application with intentional vulnerabilities)

---

## ğŸš€ Quick Start (5 Minutes)

### Prerequisites
- Docker & Docker Compose
- Python 3.9+
- Git
- API Keys: OpenAI, Anthropic (Claude), or DeepSeek

### Setup Steps

```bash
# 1. Clone this project
cd ai-devsecops-project

# 2. Clone OWASP Juice Shop
git clone https://github.com/juice-shop/juice-shop.git app/juice-shop

# 3. Install Python dependencies
pip install -r requirements.txt

# 4. Set up environment variables
cp .env.example .env
# Edit .env with your API keys

# 5. Run the complete pipeline
./run_pipeline.sh
```

---

## ğŸ“ Project Structure

```
ai-devsecops-project/
â”œâ”€â”€ app/                          # OWASP Juice Shop application
â”œâ”€â”€ pipeline/                     # CI/CD configurations
â”‚   â”œâ”€â”€ github-actions.yml       # GitHub Actions workflow
â”‚   â””â”€â”€ docker-compose.yml       # Local testing environment
â”œâ”€â”€ scanners/                     # Security scanning scripts
â”‚   â”œâ”€â”€ run_sast.sh             # SAST (Semgrep, Bandit, NodeJsScan)
â”‚   â”œâ”€â”€ run_sca.sh              # SCA (npm audit, Snyk)
â”‚   â””â”€â”€ run_dast.sh             # DAST (OWASP ZAP)
â”œâ”€â”€ parsers/                      # Report parsing
â”‚   â”œâ”€â”€ parse_reports.py        # Universal report parser
â”‚   â””â”€â”€ vulnerability_mapper.py  # Maps vulns to standards
â”œâ”€â”€ llm-policy-generator/         # AI policy generation
â”‚   â”œâ”€â”€ policy_generator.py     # Main generator (3 LLMs)
â”‚   â”œâ”€â”€ prompts.py              # Prompt templates
â”‚   â””â”€â”€ models/                 # Model configurations
â”œâ”€â”€ evaluation/                   # Evaluation framework
â”‚   â”œâ”€â”€ evaluate_policies.py    # BLEU/ROUGE-L metrics
â”‚   â””â”€â”€ reference_comparison.py # Compare with templates
â”œâ”€â”€ reference-policies/           # NIST/ISO templates
â”‚   â”œâ”€â”€ nist_csf_templates.json
â”‚   â””â”€â”€ iso27001_templates.json
â”œâ”€â”€ results/                      # Generated outputs
â”‚   â”œâ”€â”€ scan_reports/           # Raw scan results
â”‚   â”œâ”€â”€ parsed_data/            # Structured vulnerability data
â”‚   â”œâ”€â”€ generated_policies/     # AI-generated policies
â”‚   â””â”€â”€ evaluations/            # Metric results
â””â”€â”€ docs/                         # Documentation
    â”œâ”€â”€ report_template.md      # Project report
    â””â”€â”€ presentation.pptx       # Presentation slides
```

---

## ğŸ”§ Components

### 1. Security Scanning Tools

**SAST (Static Application Security Testing):**
- **Semgrep**: Multi-language static analysis
- **NodeJsScan**: Node.js specific vulnerabilities
- **npm audit**: Dependency vulnerabilities

**SCA (Software Composition Analysis):**
- **npm audit**: Known vulnerabilities in dependencies
- **Snyk**: Comprehensive dependency scanning

**DAST (Dynamic Application Security Testing):**
- **OWASP ZAP**: Web application vulnerability scanner

### 2. LLM Models (Comparative Study)

1. **GPT-4** (OpenAI)
2. **Claude Sonnet 4.5** (Anthropic)
3. **DeepSeek R1** or **LLaMA 3.3** (Open Source)

### 3. Evaluation Metrics

- **BLEU Score**: Translation quality
- **ROUGE-L**: Longest common subsequence
- **Compliance Score**: Alignment with NIST/ISO standards

---

## ğŸ¯ Pipeline Workflow

```
1. Deploy Juice Shop (Docker)
   â†“
2. Run Security Scans (SAST + SCA + DAST)
   â†“
3. Parse Reports (JSON/XML â†’ Structured Data)
   â†“
4. Generate Policies with LLMs (3 models)
   â†“
5. Evaluate Policies (BLEU/ROUGE-L)
   â†“
6. Generate Report & Visualizations
```

---

## ğŸ“Š Expected Results

### Sample Vulnerability â†’ Policy Transformation

**Input (Vulnerability Report):**
```json
{
  "vulnerability": "SQL Injection",
  "severity": "HIGH",
  "location": "login.js:45",
  "cwe": "CWE-89"
}
```

**Output (Generated Policy - NIST CSF):**
```
Control ID: PR.DS-5
Control: Protections against data leaks are implemented

Policy Statement:
All user inputs must be validated and sanitized before database queries.
Implement parameterized queries or prepared statements to prevent SQL injection.

Implementation:
- Use ORM frameworks (e.g., Sequelize) with parameter binding
- Implement input validation on both client and server side
- Deploy Web Application Firewall (WAF) rules for SQL injection patterns

Compliance Mapping:
- NIST CSF: PR.DS-5 (Data-at-rest protection)
- ISO 27001: A.14.2.5 (Secure system engineering principles)
- OWASP Top 10: A03:2021 - Injection
```

---

## ğŸ“ Deliverables Checklist

- [ ] **Functional Pipeline**: GitHub Actions or local Docker setup
- [ ] **3 Security Scans**: SAST, SCA, DAST reports
- [ ] **Report Parser**: JSON/XML parsing scripts
- [ ] **LLM Integration**: 3 models generating policies
- [ ] **Evaluation**: BLEU/ROUGE-L comparison
- [ ] **Reference Policies**: NIST CSF & ISO 27001 templates
- [ ] **Project Report**: 15-20 pages (LaTeX/Word)
- [ ] **Presentation**: 10-15 min slides
- [ ] **Demo Video**: 5-min walkthrough

---

## ğŸ”¬ Research Questions

1. How accurately do LLMs interpret technical vulnerability data?
2. Which model performs best for security policy generation?
3. Can AI-generated policies achieve >80% similarity with human-written policies?
4. What are the ethical implications of automated governance?

---

## ğŸ“š References

### DevSecOps & Security
- OWASP Top 10
- NIST Cybersecurity Framework
- ISO/IEC 27001:2022

### LLMs & AI
- Attention Is All You Need (Transformers)
- LLaMA: Open and Efficient Foundation Language Models
- Constitutional AI: Harmlessness from AI Feedback

---

## ğŸ› ï¸ Troubleshooting

### Common Issues

**Issue**: OWASP ZAP fails to start
**Solution**: Increase Docker memory to 4GB minimum

**Issue**: LLM API rate limits
**Solution**: Add retry logic with exponential backoff (already included)

**Issue**: Parsing errors
**Solution**: Check report format (JSON vs XML vs SARIF)

---

## ğŸ“§ Support

For questions or issues:
- Check `/docs/troubleshooting.md`
- Review example outputs in `/results/examples/`

---

## ğŸ“„ License

This project is for educational purposes (Final Project 2025/2026).

---

**âš¡ Ready to run?** Execute `./run_pipeline.sh` and watch the magic happen!
