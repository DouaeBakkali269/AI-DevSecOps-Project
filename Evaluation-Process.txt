# üß† LLM-Based Security Policy Generation Evaluation Framework

## 1. Overview

This document describes the evaluation framework for assessing **Large Language Models (LLMs)** that generate **security policies** for applications based on their identified vulnerabilities.
The goal is to measure the **accuracy, compliance, and quality** of AI-generated policies according to **ISO/IEC 27001:2022 Annex A Controls**.

---

## 2. Problem Definition

Modern applications undergo various security assessments such as:

* **SAST (Static Application Security Testing)**
* **DAST (Dynamic Application Security Testing)**
* **ECA (External Component Analysis)**
* **Vulnerability scans** from different tools

Each tool produces a report describing vulnerabilities in different formats.
The objective is to consolidate these reports, feed them to an LLM, and generate comprehensive **ISO 27001-aligned security policies** that address the vulnerabilities and propose corrective actions.

---

## 3. System Architecture

### 3.1 Data Aggregation

All vulnerabilities are collected and **parsed into a unified JSON structure** using a custom parsing algorithm.
This unified report serves as the input to the LLM.

**Input Example:**

```json
{
  "application": "MyApp",
  "vulnerabilities": [
    {
      "id": "VULN-001",
      "type": "SQL Injection",
      "severity": "High",
      "source": "SAST",
      "description": "Unsanitized user input in /api/login"
    },
    {
      "id": "VULN-002",
      "type": "Weak Password Policy",
      "severity": "Medium",
      "source": "ECA",
      "description": "Password length less than 8 characters"
    }
  ]
}

3.2 LLM Task Definition

Each model receives a system prompt that establishes its expert role:

    ‚ÄúYou are a cybersecurity and information security policy expert specializing in ISO/IEC 27001:2022 Annex A Controls. Your task is to analyze the provided vulnerability scans and generate comprehensive, actionable security policies that mitigate the identified issues and align with ISO 27001 controls.‚Äù

3.3 Output Format

The model must output policies in a structured JSON format:
JSON

{
  "policies": [
    {
      "policy_title": "Database Input Validation Policy",
      "iso_27001_control_reference": "A.8.25 ‚Äì Secure Coding",
      "severity": "High",
      "vulnerability_summary": [
        "SQL Injection vulnerability in /api/login"
      ],
      "policy_content": "All database queries must use parameterized statements...",
      "corrective_actions": [
        "Implement input sanitization and ORM parameterization",
        "Add automated validation to backend endpoints"
      ]
    },
    {
      "policy_title": "Password Complexity Policy",
      "iso_27001_control_reference": "A.5.17 ‚Äì Authentication Information",
      "severity": "Medium",
      "vulnerability_summary": [
        "Weak password policy (less than 8 characters)"
      ],
      "policy_content": "User passwords must meet a minimum complexity requirement...",
      "corrective_actions": [
        "Enforce password length ‚â• 12",
        "Add uppercase, lowercase, numeric, and special character requirements"
      ]
    }
  ]
}

4. Reference Policy Generation

To evaluate other models, we need a ground-truth reference for comparison.

Since no standardized dataset of vulnerabilities with corresponding ISO 27001-aligned policies exists, the reference policies will be generated using the best available model:

    Model: Kimi-K2-Thinking (moonshotai/kimi-k2-thinking) (Second best llm model according to "https://artificialanalysis.ai/") (security-optimized, reasoning enabled)

    Prompt Context: Full vulnerability dataset + ISO 27001 Annex A controls

    Output: High-quality, human-verified policy set

This reference is treated as the gold standard for benchmarking all other models.

5. Evaluation Process

5.1 Model Set

A total of 10 models (closed- and open-source) will be evaluated, including but not limited to:

    openai/gpt-5-mini
    openai/gpt-5-nano
    anthropic/claude-haiku-4.5
    x-ai/grok-4-fast
    minimax/minimax-m2
    meta-llama/llama-3.3-70b-instruct
    z-ai/glm-4.6
    google/gemini-2.5-flash


5.2 Evaluation Metrics

    BLEU Score

        Measures lexical similarity between generated and reference policies.

        Evaluates how closely the wording matches.

    ROUGE-L Score

        Measures semantic similarity and coverage.

        Captures overlap in meaning, even with different phrasing.

    Custom Semantic Benchmark (AI-as-a-Judge)

        A specialized evaluation agent (AI judge) compares each policy with the reference along multiple dimensions:

Criterion	Description	Scale
ISO 27001 Alignment	How well the policy aligns with the correct Annex A control	0‚Äì5
Policy Completeness	Coverage of relevant vulnerabilities and controls	0‚Äì5
Actionability	Practicality and specificity of corrective actions	0‚Äì5
Technical Accuracy	Correctness of mitigation details	0‚Äì5
Linguistic Quality	Clarity, coherence, and professional tone	0‚Äì5

Total Score: Average across all criteria (0‚Äì5)

6. Evaluation Pipeline

    Parse and normalize vulnerability scan outputs.

    Feed the parsed input to each LLM with the standardized system prompt.

    Collect JSON-formatted policy outputs.

    Compare each output to the reference policies using:

        BLEU

        ROUGE-L

        AI-Judge (custom benchmark)

    Aggregate results into a final scorecard per model.

    Analyze results across:

        Model type (open vs closed)

        Token context length

        Reasoning capability

        ISO 27001 alignment fidelity

7. Output Analysis and Visualization

Final outputs will include:

    Quantitative Table: BLEU, ROUGE-L, and AI-Judge scores per model

    Radar Chart: Comparing ISO 27001 alignment, completeness, and accuracy

    Qualitative Review: Examples of well-aligned and poorly-aligned policy generations

8. Expected Outcome

The evaluation framework will:

    Quantify how accurately and comprehensively different LLMs can generate ISO 27001-aligned policies.

    Identify best-performing models in cybersecurity compliance policy generation.

    Provide a repeatable benchmark for future research on AI-driven security policy automation.

9. Future Enhancements

    Incorporate human security expert validation for further calibration.

    Expand benchmark to NIST SP 800-53, OWASP ASVS, and SOC 2 frameworks.

    Develop an automated evaluation dashboard for continuous testing and improvement.

Author: Omar BEHRI Version: 1.0 Last Updated: 2025-11-13